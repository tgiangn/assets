<!DOCTYPE html>
<html lang="en">
<head>
    <title>Detect object using pre trained model in Tensorflow.js</title>
    <meta charset="utf-8">
    <style>
        body {
        font-family: helvetica, arial, sans-serif;
        margin: 2em;
        color: #3D3D3D;
        }
        video {
        display: block;
        }

        section {
        opacity: 1;
        transition: opacity 500ms ease-in-out;
        }
        .removed {
        display: none;
        }

        .invisible {
        opacity: 0.2;
        }

        .camView {
        position: relative;
        float: left;
        width: calc(100% - 20px);
        margin: 10px;
        cursor: pointer;
        }

        .camView p {
        position: absolute;
        padding: 5px;
        background-color: rgba(255, 111, 0, 0.85);
        color: #FFF;
        border: 1px dashed rgba(255, 255, 255, 0.7);
        z-index: 2;
        font-size: 12px;
        }

        .highlighter {
        background: rgba(0, 255, 0, 0.25);
        border: 1px dashed #fff;
        z-index: 1;
        position: absolute;
        }
        @media all and (max-width: 699px) and (min-width: 520px), (min-width: 1151px) {
           body {
            background: #ccc;
            font-size: 3.9vw;
          }
            h1 {
            font-style: italic;font-size: 5.9vw;
            color: #FF6F00;
            }            
        }

    </style>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js" type="text/javascript"></script>
    <!-- Load the coco-ssd model to use to recognize things in images -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    
</head>
<body>
    <section id="demos" class="invisible">
        <h1>Latest</h1>
        <p>Hold some objects up close to your webcam to get a real-time classification! When ready click "enable webcam" below and accept access to the webcam when the browser asks (check the top left of your window)</p>
        
        <div id="liveView" class="webcam">
          <button id="webcamButton">Enable Webcam</button>
          <video id="webcam" autoplay width="100%" height="480"></video>
        </div>
      </section>
    <script>
        const video = document.getElementById('webcam');
        const liveView = document.getElementById('liveView');
        const demosSection = document.getElementById('demos');
        const enableWebcamButton = document.getElementById('webcamButton');
        function getUserMediaSupported(){
            return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia)
        }
        if(getUserMediaSupported()){
            enableWebcamButton.addEventListener('click', enableCam);
        }
        else{
            alert('User Media is not supported by your browser.');
        }
        function enableCam(event){
            if(!model){return;}
            event.target.classList.add('removed');
            const constraints = {
                video:true
            };
            navigator.mediaDevices.getUserMedia(constraints).then(function(stream){
                video.srcObject = stream;
                video.addEventListener('loaderdata', predictWebcam);
            });
        }
        var children = [];
        function predictWebcam(){
            // Now let's start classifying a frame in the stream.
            model.detect(video).then(function (predictions) {
                // Remove any highlighting we did previous frame.
                for (let i = 0; i < children.length; i++) {
                liveView.removeChild(children[i]);
                }
                children.splice(0);
                
                // Now lets loop through predictions and draw them to the live view if
                // they have a high confidence score.
                for (let n = 0; n < predictions.length; n++) {
                // If we are over 66% sure we are sure we classified it right, draw it!
                if (predictions[n].score > 0.66) {
                    const p = document.createElement('p');
                    p.innerText = predictions[n].class  + ' - with ' 
                        + Math.round(parseFloat(predictions[n].score) * 100) 
                        + '% confidence.';
                    p.style = 'margin-left: ' + predictions[n].bbox[0] + 'px; margin-top: '
                        + (predictions[n].bbox[1] - 10) + 'px; width: ' 
                        + (predictions[n].bbox[2] - 10) + 'px; top: 0; left: 0;';

                    const highlighter = document.createElement('div');
                    highlighter.setAttribute('class', 'highlighter');
                    highlighter.style = 'left: ' + predictions[n].bbox[0] + 'px; top: '
                        + predictions[n].bbox[1] + 'px; width: ' 
                        + predictions[n].bbox[2] + 'px; height: '
                        + predictions[n].bbox[3] + 'px;';

                    liveView.appendChild(highlighter);
                    liveView.appendChild(p);
                    children.push(highlighter);
                    children.push(p);
                }
                }
                
                // Call this function again to keep predicting when the browser is ready.
                window.requestAnimationFrame(predictWebcam);
            });
        }
        var model = undefined;
        demosSection.classList.remove('invisible');
        cocoSsd.load().then(function (loadedModel) {
            model = loadedModel;
            // Show demo section now model is ready to use.
            demosSection.classList.remove('invisible');
        });
        
    </script>
</body>
</html>
